{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"檢視空值及零值\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def analyze_nan_and_zero_values(\n",
    "    data, threshold, sort_column=\"零值+NAN佔比 (%)\", ascending=False\n",
    "):\n",
    "    \"\"\"\n",
    "    檢查0值和 nan 的數量\n",
    "    threshold 為 百分比，例threshold=20，會回傳 零值+NAN佔比 (%) 大於20% 的\n",
    "    當 threshold = 0 會回傳全部\n",
    "    \"\"\"\n",
    "\n",
    "    # 如果輸入是文件路徑，讀取CSV文件並轉換成Pandas DataFrame\n",
    "\n",
    "    if isinstance(data, str):\n",
    "\n",
    "        file_source_pd = pd.read_csv(data)\n",
    "\n",
    "    # 如果輸入是Pandas DataFrame，直接使用它\n",
    "\n",
    "    elif isinstance(data, pd.DataFrame):\n",
    "\n",
    "        file_source_pd = data\n",
    "\n",
    "    else:\n",
    "\n",
    "        raise ValueError(\n",
    "            \"Invalid input type. Input must be either file path or Pandas DataFrame.\"\n",
    "        )\n",
    "\n",
    "    # 計算這個範圍內每一欄的空白值(NaN)數量\n",
    "\n",
    "    nan_values_per_column_in_range = file_source_pd.isnull().sum(axis=0)\n",
    "\n",
    "    # 計算每個欄位的總數據量\n",
    "\n",
    "    total_data_per_column = len(file_source_pd)\n",
    "\n",
    "    # 計算每個欄位的空白值(NaN)佔比\n",
    "\n",
    "    nan_percentage_per_column = (\n",
    "        nan_values_per_column_in_range / total_data_per_column\n",
    "    ) * 100\n",
    "\n",
    "    # 計算這個範圍內每一欄的零值數量\n",
    "\n",
    "    zero_values_per_column_in_range = (file_source_pd == 0).sum(axis=0)\n",
    "\n",
    "    # 計算每個欄位的零值佔比\n",
    "\n",
    "    zero_percentage_per_column = (\n",
    "        zero_values_per_column_in_range / total_data_per_column\n",
    "    ) * 100\n",
    "\n",
    "    # 計算每個欄位的零值和NaN值的總數\n",
    "\n",
    "    total_zero_and_nan_per_column = (\n",
    "        zero_values_per_column_in_range + nan_values_per_column_in_range\n",
    "    )\n",
    "\n",
    "    # 計算每個欄位的零值和NaN值總數的佔比\n",
    "\n",
    "    total_zero_and_nan_percentage_per_column = (\n",
    "        total_zero_and_nan_per_column / total_data_per_column\n",
    "    ) * 100\n",
    "\n",
    "    # 將結果轉換為 DataFrame\n",
    "\n",
    "    values_df = pd.DataFrame(\n",
    "        {\n",
    "            \"欄位名稱\": nan_values_per_column_in_range.index,\n",
    "            \"零值+NAN佔比 (%)\": total_zero_and_nan_percentage_per_column.values.round(\n",
    "                2\n",
    "            ),\n",
    "            \"空白值(NaN)數量\": nan_values_per_column_in_range.values,\n",
    "            \"空白值(NaN)佔比 (%)\": nan_percentage_per_column.values.round(2),\n",
    "            \"零值數量\": zero_values_per_column_in_range.values,\n",
    "            \"零值佔比 (%)\": zero_percentage_per_column.values.round(2),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # 將 DataFrame 存儲到 CSV 檔案中\n",
    "    values_df.to_csv(\"零值與空白值統計.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # 如果 threshold 等於 0，則返回所有欄位\n",
    "    if threshold == 0:\n",
    "        return values_df\n",
    "\n",
    "    # 篩選出 '零值+NAN佔比 (%)' 大於指定閾值的欄位\n",
    "\n",
    "    filtered_values_df = values_df[values_df[\"零值+NAN佔比 (%)\"] > threshold]\n",
    "\n",
    "    # 根據指定的列進行排序\n",
    "\n",
    "    sorted_values_df = filtered_values_df.sort_values(\n",
    "        by=sort_column, ascending=ascending\n",
    "    )\n",
    "\n",
    "    return sorted_values_df\n",
    "\n",
    "\n",
    "# 測試\n",
    "\n",
    "\n",
    "# result_df = analyze_nan_and_zero_values(clean_data, threshold=0, sort_column='欄位名稱', ascending=False)\n",
    "\n",
    "\n",
    "# print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"分類指標 僅適用二元分法\"\"\"\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 忽略警告用的\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# 解決字體問題\n",
    "plt.rcParams[\"font.family\"] = [\"Microsoft YaHei\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "\n",
    "def evaluate_model_multi_class(y_test, y_pred):\n",
    "    # 從y_test自動讀取類別數\n",
    "    num_classes = len(np.unique(y_test))\n",
    "\n",
    "    # # 計算和顯示混淆矩陣\n",
    "    # cm = confusion_matrix(y_test, y_pred)\n",
    "    # df_cm = pd.DataFrame(cm, index=range(num_classes), columns=range(num_classes))\n",
    "    # # 轉換為比例\n",
    "    # cm_ratio = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # # plt.figure(figsize=(10,7))\n",
    "    # # 使用藍色的色調 'Blues'\n",
    "    # sn.heatmap(cm_ratio, annot=True, fmt=\".0%\", cmap=\"Blues\")\n",
    "    # plt.title('Confusion matrix (混淆矩陣)\\n', y=1.1)\n",
    "    # plt.ylabel('Actual label (實際標籤)\\n')\n",
    "    # plt.xlabel('Predicted label (預測標籤)\\n')\n",
    "    # plt.show()\n",
    "\n",
    "    # 計算和顯示每個類的Accuracy、Precision、Recall和F1 Score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    print(f\"Accuracy (準確率): {accuracy:.2%}\")\n",
    "    print(f\"Precision (精確率) - Macro Average: {precision:.2%}\")\n",
    "    print(f\"Recall (召回率) - Macro Average: {recall:.2%}\")\n",
    "    print(f\"F1 Score (F1分數) - Macro Average: {f1:.2%}\")\n",
    "\n",
    "\n",
    "# 使用範例\n",
    "# y_pred = model.predict(X_test)\n",
    "# evaluate_model_multi_class(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"(還沒成功)分類指標 用於多模型\"\"\"\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 忽略警告用的\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "\n",
    "def many_models_evaluate_model_multi_class(y_test, y_pred):\n",
    "    # 從y_test自動讀取類別數\n",
    "    num_classes = len(np.unique(y_test))\n",
    "\n",
    "    # 計算和顯示混淆矩陣\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    df_cm = pd.DataFrame(cm, index=range(num_classes), columns=range(num_classes))\n",
    "    # 轉換為比例\n",
    "    cm_ratio = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sn.heatmap(cm_ratio, annot=True, fmt=\".0%\", cmap=\"Blues\")\n",
    "    plt.title(\"Confusion matrix (混淆矩陣)\\n\", y=1.1)\n",
    "    plt.ylabel(\"Actual label (實際標籤)\\n\")\n",
    "    plt.xlabel(\"Predicted label (預測標籤)\\n\")\n",
    "    plt.show()\n",
    "\n",
    "    # 計算各項指標\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "    # 返回指標值\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# file_path = r\"..\\飲料店總表0307final01_補上人氣_補值_xlsxclustered_HG_data.xlsx\"\n",
    "file_path = r\"..\\飲料店總表0307final01_補上人氣_補值_hg.xlsx\"\n",
    "# dataset = pd.read_csv(file_path, sep=\",\", encoding=\"UTF-8\")\n",
    "\n",
    "dataset = pd.read_excel(file_path)\n",
    "# print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"selected_data\n",
    "\"\"\"\n",
    "\n",
    "selected_data = dataset[\n",
    "    [\n",
    "        \"star\",\n",
    "        \"school_counts\",\n",
    "        \"drink_counts\",\n",
    "        \"train_counts\",\n",
    "        \"youbike_counts\",\n",
    "        \"bus_counts\",\n",
    "        \"park_counts\",\n",
    "        \"night_market_counts\",\n",
    "        \"sports_facilities_counts\",\n",
    "        \"mrt_counts\",\n",
    "        \"movie_theater_counts\",\n",
    "        \"hospital_counts\",\n",
    "        \"salary_income_median\",\n",
    "        \"people_flow_mean\",\n",
    "        \"knock_down_price_mean\",\n",
    "        \"weekend_open\",\n",
    "        \"road_area_ratio\",\n",
    "        \"age\",\n",
    "        \"weekday_working_hours_average\",\n",
    "        # \"comment\",\n",
    "        # \"people_flow_average\",\n",
    "        \"popularity\",\n",
    "        # \"KMEANS\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# selected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  popularity_category          最小值          最大值    數量\n",
      "0                   0     0.000000   441.227668  3180\n",
      "1                   1   441.257427   882.514854   635\n",
      "2                   2   882.637890  1320.782089   321\n",
      "3                   3  1325.771070  1758.006505   178\n",
      "4                   4  1767.739056  2206.287135   112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\AppData\\Local\\Temp\\ipykernel_13900\\2120413078.py:34: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selected_data.groupby(\"popularity_category\")[\"popularity\"]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"因為數值分布差很多 刪掉極端\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 直接在原始 DataFrame 中刪除 'popularity' 小於 8726.779 的行\n",
    "selected_data = selected_data[selected_data[\"popularity\"] <= 2213.641425]\n",
    "\n",
    "# 使用 pd.cut 根據數值大小劃分 'popularity' 欄位\n",
    "\n",
    "# 計算數據範圍\n",
    "min_val = selected_data[\"popularity\"].min()\n",
    "max_val = selected_data[\"popularity\"].max()\n",
    "\n",
    "# 創建五個分組的邊界值\n",
    "bins = np.linspace(min_val, max_val, 6)\n",
    "\n",
    "# 使用 pd.cut 來分組\n",
    "selected_data[\"popularity_category\"] = pd.cut(\n",
    "    selected_data[\"popularity\"],\n",
    "    bins=bins,\n",
    "    include_lowest=True,  # 確保包括最低值\n",
    "    labels=[0, 1, 2, 3, 4],  # 這是每個範圍的標籤\n",
    ")\n",
    "\n",
    "\n",
    "# 打印新的分類結果和每類的數量\n",
    "\n",
    "# print(selected_data['popularity_category'].value_counts().sort_index())\n",
    "\n",
    "\n",
    "# 建立統計信息表格\n",
    "\n",
    "summary_df = (\n",
    "    selected_data.groupby(\"popularity_category\")[\"popularity\"]\n",
    "    .agg(最小值=\"min\", 最大值=\"max\", 數量=\"size\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"轉位數\"\"\"\n",
    "\n",
    "selected_data[\"age\"] = selected_data[\"age\"].round(2)\n",
    "selected_data[\"road_area_ratio\"] = selected_data[\"road_area_ratio\"].round(3)\n",
    "\n",
    "\n",
    "# dataset['brand'] = dataset['brand'].fillna(-1)\n",
    "# dataset['Saturday_open_hours'] = dataset['Saturday_open_hours'].fillna(-1)\n",
    "# dataset['Sunday_open_hours'] = dataset['Sunday_open_hours'].fillna(-1)\n",
    "\n",
    "\n",
    "# X = dataset.drop(\n",
    "#     ['comment','star','people_flow_average','popularity',\"KMEANS\"], axis=1\n",
    "# )\n",
    "y = selected_data[\"popularity_category\"]\n",
    "X = selected_data.drop([\"popularity\", \"popularity_category\"], axis=1)\n",
    "\n",
    "# y = dataset[\"KMEANS\"]\n",
    "y = y.to_frame()\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>欄位名稱</th>\n",
       "      <th>零值+NAN佔比 (%)</th>\n",
       "      <th>空白值(NaN)數量</th>\n",
       "      <th>空白值(NaN)佔比 (%)</th>\n",
       "      <th>零值數量</th>\n",
       "      <th>零值佔比 (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>popularity_category</td>\n",
       "      <td>71.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3180</td>\n",
       "      <td>71.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  欄位名稱  零值+NAN佔比 (%)  空白值(NaN)數量  空白值(NaN)佔比 (%)  零值數量  \\\n",
       "0  popularity_category         71.85           0             0.0  3180   \n",
       "\n",
       "   零值佔比 (%)  \n",
       "0     71.85  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_nan_and_zero_values(X, 0, sort_column=\"零值+NAN佔比 (%)\", ascending=False)\n",
    "analyze_nan_and_zero_values(y, 0, sort_column=\"零值+NAN佔比 (%)\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割訓練和測試\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# test_size 切的尺寸 30% random_state讓抽取可以是穩定的結果(第一次抽根第十次抽是一樣的)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=25\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 將所有模型結果匯成一張表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (準確率): 69.50%\n",
      "Precision (精確率) - Macro Average: 37.33%\n",
      "Recall (召回率) - Macro Average: 20.28%\n",
      "F1 Score (F1分數) - Macro Average: 17.18%\n",
      "Accuracy (準確率): 69.58%\n",
      "Precision (精確率) - Macro Average: 24.82%\n",
      "Recall (召回率) - Macro Average: 20.52%\n",
      "F1 Score (F1分數) - Macro Average: 17.75%\n",
      "Accuracy (準確率): 69.88%\n",
      "Precision (精確率) - Macro Average: 30.29%\n",
      "Recall (召回率) - Macro Average: 20.93%\n",
      "F1 Score (F1分數) - Macro Average: 18.29%\n",
      "Accuracy (準確率): 69.65%\n",
      "Precision (精確率) - Macro Average: 13.93%\n",
      "Recall (召回率) - Macro Average: 20.00%\n",
      "F1 Score (F1分數) - Macro Average: 16.42%\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# 模型檔案位置\n",
    "model_paths = [\n",
    "    # \"模型\\\\AdaBoost_model_best.joblib\",\n",
    "    # \"模型\\\\Bayesion_classifier_model_best.joblib\",\n",
    "    \"模型\\\\best_randomforest_model.joblib\",\n",
    "    \"模型\\\\lr_model_best.joblib\",\n",
    "    # \"模型\\\\MultinomialNB_model_best.joblib\",\n",
    "    # \"模型\\\\svc_best.joblib\",\n",
    "    \"模型\\\\XGBoost model_best.joblib\",\n",
    "    \"模型\\\\best_mlp_model.joblib\",\n",
    "]\n",
    "# 載入模型\n",
    "models = [joblib.load(model_path) for model_path in model_paths]\n",
    "\n",
    "# 創建一個空的DataFrame用於存儲結果\n",
    "results_df = pd.DataFrame\n",
    "\n",
    "# 計算並顯示每個模型的準確率\n",
    "for model, path in zip(models, model_paths):\n",
    "    y_pred = model.predict(X_test)\n",
    "    evaluate_model_multi_class(y_test, y_pred)\n",
    "    # results_df\n",
    "    # acc, prec, rec, f1 = evaluate_model_multi_class(y_test, y_pred)  # 獲取評估指標\n",
    "    # # 更新DataFrame\n",
    "    # results_df = results_df.append({'Model': path.split('\\\\')[-1], 'Accuracy': acc, 'Precision': prec, 'Recall': rec, 'F1 Score': f1}, ignore_index=True)\n",
    "# 打印結果\n",
    "# print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bagging_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"非傳統bagging，屬於類似stacking\"\"\"\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "bagging_model = BaggingClassifier(n_estimators=len(models), random_state=42)\n",
    "\n",
    "# # 計算並顯示每個模型的準確率\n",
    "# for model, path in zip(models, model_paths):\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     acc = accuracy_score(y_test, y_pred)\n",
    "#     print(f\"{path.split('\\\\')[-1]} 的準確率: {acc}\")\n",
    "#     evaluate_model_multi_class(y_test, y_pred)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 訓練 Bagging 模型\n",
    "X_train_preds = np.array([model.predict(X_train) for model in models]).T\n",
    "X_test_preds = np.array([model.predict(X_test) for model in models]).T\n",
    "bagging_model.fit(X_train_preds, y_train)\n",
    "\n",
    "# 計算 Bagging 模型的準確率\n",
    "bagging_model.fit(X_train_preds, y_train)\n",
    "\n",
    "y_pred_bag = bagging_model.predict(X_test_preds)\n",
    "acc_bag = accuracy_score(y_test, y_pred_bag)\n",
    "print(f\"Bagging 模型的準確率: {acc_bag}\")\n",
    "\n",
    "evaluate_model_multi_class(y_test, y_pred_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 自定義類別來包含所有子模型和Bagging模型\n",
    "class CompleteModel:\n",
    "    def __init__(self, base_models, bagging_model):\n",
    "        self.base_models = base_models  # 存儲所有子模型\n",
    "        self.bagging_model = bagging_model  # 存倲Bagging模型\n",
    "\n",
    "    def predict(self, X):\n",
    "        # 對每個子模型進行預測並將結果堆疊起來\n",
    "        X_preds = np.array([model.predict(X) for model in self.base_models]).T\n",
    "        # 使用Bagging模型對堆疊後的預測進行最終預測\n",
    "        return self.bagging_model.predict(X_preds)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # 對每個子模型進行預測並將結果堆疊起來\n",
    "        X_preds = np.array([model.predict(X) for model in self.base_models]).T\n",
    "        # 使用Bagging模型對堆疊後的數據進行訓練\n",
    "        self.bagging_model.fit(X_preds, y)\n",
    "\n",
    "\n",
    "# 載入你的子模型\n",
    "base_models = [joblib.load(model_path) for model_path in model_paths]\n",
    "# 創建Bagging模型實例（這個步驟假設你已經有一個訓練好的Bagging模型）\n",
    "bagging_model = BaggingClassifier(n_estimators=len(base_models), random_state=42)\n",
    "# 如果你已經訓練好了Bagging模型，你應該這樣初始化你的CompleteModel\n",
    "bagging_complete_model = CompleteModel(base_models, bagging_model)\n",
    "\n",
    "bagging_complete_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# 假設你已經有了訓練好的CompleteModel實例\n",
    "# 保存整個模型\n",
    "# joblib.dump(complete_model, 'complete_model.joblib')\n",
    "\n",
    "# 當需要時，重新載入模型並進行預測\n",
    "# loaded_model = joblib.load('complete_model.joblib')\n",
    "# predictions = loaded_model.predict(X_new)  # X_new是新的輸入數據\n",
    "y_pred_bag = bagging_complete_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bagging_complete_model.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"輸出模型\"\"\"\n",
    "\n",
    "from joblib import dump\n",
    "\n",
    "# 保存模型\n",
    "dump(bagging_complete_model, \"bagging_complete_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 假設 base_models 是你所有預訓練好的基模型列表\n",
    "base_models = [joblib.load(model_path) for model_path in model_paths]\n",
    "\n",
    "# 載入 Bagging 分類器模型\n",
    "bagging_model_loaded = load(\"bagging_model.joblib\")\n",
    "\n",
    "# 使用所有子模型對原始數據X進行預測，並將這些預測結果堆疊起來作為新的特徵集\n",
    "X_transformed = np.array([model.predict(X) for model in base_models]).T\n",
    "\n",
    "# 使用轉換後的特徵集進行預測\n",
    "y_pred = bagging_model_loaded.predict(X_transformed)\n",
    "\n",
    "# 使用分類指標進行評估\n",
    "print(classification_report(y, y_pred))\n",
    "\n",
    "# 如果你有一個評估函數，也可以使用它來評估模型\n",
    "# evaluate_model_multi_class(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (準確率): 75.15%\n",
      "Precision (精確率) - Macro Average: 88.48%\n",
      "Recall (召回率) - Macro Average: 29.58%\n",
      "F1 Score (F1分數) - Macro Average: 33.69%\n"
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "\n",
    "# 載入完整模型\n",
    "bagging_model_loaded = load(\"bagging_complete_model.joblib\")\n",
    "\n",
    "# 使用載入的模型進行預測，X_new是新的輸入數據\n",
    "y_pred_bag = bagging_model_loaded.predict(X_train)\n",
    "evaluate_model_multi_class(y_train, y_pred_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 生成混淆矩陣\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "# 轉換為比例\n",
    "cm_ratio = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# 使用Seaborn畫出混淆矩陣的熱力圖\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm_ratio, annot=True, fmt=\".2f\", cmap=\"Blues\")  # fmt='.2f' 指定顯示兩位小數\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 假設 models 是你之前加載的模型列表\n",
    "estimators = [(f\"model_{i}\", model) for i, model in enumerate(models)]\n",
    "\n",
    "# 建立一個硬投票分類器\n",
    "voting_clf = VotingClassifier(estimators=estimators, voting=\"hard\")\n",
    "\n",
    "# 訓練 voting_clf\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# 進行預測，假設有一個測試資料集 X_test\n",
    "y_pred_voting = voting_clf.predict(X_test)\n",
    "\n",
    "\n",
    "# 使用交叉驗證來評估模型\n",
    "scores = cross_val_score(voting_clf, X, y, cv=5)  # cv 是交叉驗證的摺數\n",
    "\n",
    "\n",
    "evaluate_model_multi_class(y_test, y_pred_voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"輸出模型\"\"\"\n",
    "\n",
    "from joblib import dump\n",
    "\n",
    "# 保存模型\n",
    "dump(voting_clf, \"voting_clf.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 載入模型\n",
    "voting_clf_loaded = load(\"voting_clf.joblib\")\n",
    "\n",
    "# 假設你已經有了一組新的預測數據 X_new\n",
    "# 使用載入的模型進行預測\n",
    "y_pred_voting = voting_clf_loaded.predict(X)\n",
    "\n",
    "# 假設你也有相應的真實標籤 y_new（用於評估）\n",
    "# 使用分類指標進行評估\n",
    "print(classification_report(y, y_pred_voting))\n",
    "\n",
    "evaluate_model_multi_class(y, y_pred_voting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier  # 導入堆疊分類器(StackingClassifier)\n",
    "from sklearn.linear_model import LogisticRegression  # 用於最終分類器\n",
    "\n",
    "\n",
    "# 假設 models 是你之前加載的模型列表，其中每個模型都作為一個基學習器(base learner)\n",
    "estimators = [(f\"model_{i}\", model) for i, model in enumerate(models)]\n",
    "\n",
    "# 建立一個堆疊分類器\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression()\n",
    ")\n",
    "\n",
    "# X_train, y_train 是您的訓練數據及其標籤\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# 計算訓練集上的準確率\n",
    "accuracy = stacking_clf.score(X_train, y_train)\n",
    "print(\"Training accuracy:\", accuracy)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 進行5折交叉驗證\n",
    "scores = cross_val_score(stacking_clf, X_train, y_train, cv=5)\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"stacking Average score:\", scores.mean())\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 重新訓練模型\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# 進行預測\n",
    "y_pred_stacking = stacking_clf.predict(X_test)\n",
    "\n",
    "# \"\"\"輸出模型\"\"\"\n",
    "# from joblib import dump, load\n",
    "\n",
    "# # 保存模型\n",
    "# dump(stacking_clf, \"stacking_not_adaboost.joblib\")\n",
    "\n",
    "evaluate_model_multi_class(y_test, y_pred_stacking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# 初始化梯度提升機模型\n",
    "# 可以透過調整n_estimators、learning_rate和max_depth等參數進行優化\n",
    "# 請根據您的數據和需求進行調整\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42\n",
    ")\n",
    "\n",
    "# 將已經訓練好的模型作為初始估計器傳遞給GradientBoostingClassifier\n",
    "gb_model.estimators_ = models\n",
    "\n",
    "# 訓練模型\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# 預測測試集\n",
    "y_pred_boosting = gb_model.predict(X_test)\n",
    "\n",
    "# 評估模型性能\n",
    "evaluate_model_multi_class(y_test, y_pred_boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"輸出模型\"\"\"\n",
    "\n",
    "from joblib import dump\n",
    "\n",
    "# 保存模型\n",
    "dump(svc_best, \"svc_best.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
